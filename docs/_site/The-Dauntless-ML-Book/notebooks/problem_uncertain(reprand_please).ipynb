{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "1. Back story: how human solve problem under uncertainty\n",
    "2. Hard problems \n",
    "3. Need for a real-world feasible and affordable solution\n",
    "4. find quotes \n",
    "\n",
    "### plan\n",
    "1. the story for task scheduling \n",
    "2. develop version 1 (simplified problem)\n",
    "3. develop version 2 (sophisticated algorithm)\n",
    "4. develop version 3 (solver based)\n",
    "5. develop version 4 (combucb1 bandit)\n",
    "6. More examples: shortest path (TS-comb)\n",
    "7. More examples: matching (Linear Bayesian with TF-probability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Dauntless Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- TODO: Change the paragraph to the purpose of the chapter\n",
    "\n",
    "In many real-world situations, we face a well-known problem like scheduling a set of conflicting tasks or finding the shortest path. Although we know much about these problems and have good algorithms to solve them, we often run into the frustrating case of not having full info needed to run the algorithm. For example, we may know the tasks we want to schedule but do not know who much time each task will take. This section will introduce you to algorithms that will help you run your favorite algorithm to solve problems you are not 100% certain about. To build intuition, we will use task scheduling as a running example. We will start with a simple educational version of the problem and gradually add some complexity that you may face in real-world scenarios. At the end of the chapter, we will reach a dauntless algorithm that will enable you to solve complex problems that you are not even certain about. With no further do let's get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many phone calls?\n",
    "Our friend Reco got an interesting job in a marketing company, he has the number of clients he needs to contact to market the company products to them. Reco has access to the clients' calendar, and he is working on picking time slots to make the best of his time, the goal is to talk to as many clients as he can.\n",
    "\n",
    "<img src=\"../figures/Constraint graph.PNG\" width=\"600px\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version1: the activity selection problem\n",
    "As usual, Reko starts with simple solutions first. Reco noticed if we have only one slot per day for each client this problem is similar to the activity scheduling problem. In this problem, the input is a set of tasks and there start and end time, the tasks have conflicting periods and one person can only perform one task at a time. The goal is to select the maximum number of tasks that can be executed by one person. One solution for activity selection problem is the greedy solution, you start with the task that finish first then pick tasks that finish first and does not conflict with the last task you have selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [(\"T1\", 8.50, 9.50), \n",
    "         (\"T2\", 9.25, 10.25),\n",
    "         (\"T3\", 9.30, 10.75),\n",
    "         (\"T4\", 10.25, 11.50),\n",
    "         (\"T5\", 12.00, 13.50),\n",
    "         (\"T6\", 12.25, 13.75)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('T1', 8.5, 9.5), ('T4', 10.25, 11.5), ('T5', 12.0, 13.5)]\n"
     ]
    }
   ],
   "source": [
    "# Algorithm: Activity selection problem\n",
    "# inputs: tasks with start and finish times\n",
    "# output: selected_tasks list of maximum none confilecting tasks\n",
    "\n",
    "#1. stort data by finish time\n",
    "tasks = sorted(tasks, key=lambda x: x[2])\n",
    "\n",
    "#2. start with the taks that have the earliest finsh time\n",
    "last_selected_task = tasks.pop(0)\n",
    "last_selected_task_finish = last_selected_task[2]\n",
    "selected_tasks = [last_selected_task]\n",
    "\n",
    "# add tasks with earlist finish that does not conflict with the seleected tasks\n",
    "while len(tasks) > 0:\n",
    "    task = tasks.pop(0)\n",
    "    task_start = task[1]\n",
    "    if task_start >= last_selected_task_finish:\n",
    "        last_selected_task_finish = task[2]\n",
    "        selected_tasks += [task]\n",
    "\n",
    "\n",
    "print (selected_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tabulate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-822e87843aea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtabulate\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtabulate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselected_tasks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"task\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"start time\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"finish time\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"task\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tabulate'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import math\n",
    "\n",
    "df = pd.DataFrame(selected_tasks, columns=[\"task\", \"start time\", \"finish time\"]).set_index(\"task\")\n",
    "print(tabulate(df, headers='keys', tablefmt='psql'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By applying the greedy algorithm on our example, Reco can talk to 4 clients on that day, Reco can call Clients C1, C3 and C5 with no conflicts. The greedy solution is optimal, to see that, letâ€™s assume we have an optimal solution that does not start with the first finishing task, if we replace the first task in the solution with the task that is earliest finishing task (note that no time conflict here), then we will have another optimal solution. Now we need to select the optimal tasks from the remaining tasks, so we are solving the Activity selection problem again on small problem size, we can apply the same logic until the smaller problem reach size zero. \n",
    "\n",
    "This solution seems to work fine, however, we could better model our problem. first, in reality, Reco will not use all the slot time to make the call, for example, if the slot is 45 Mins, Reco may only use 30 Mis of them. Moreover, clients have different concerns and personalities, for easy-going clients, Reco could finish in 15 Mins and for other less pleasant clients, he may need up to an hour. Second, some clients are more valuable to the company, so Reco needs to take client value into consideration. To handle these issues, Reko thought of another iteration of the problem, it is called the weighted activity selection problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 2: Weighted activity selection problem\n",
    "In this version, Reco divided each time slot on 15 min bases, so if the client is free for 1 hour he will consider 15, 30, 45 and 60 mins, then based on his experience, Reco will pick a time in each slot that is sufficient for each client. Note that, in this setting, you can start after the slot starting time, for example, if the client is free from 10:00 AM - 11:00 AM and he needs 45 mins, Reco will consider two options, either 10:00 AM - 10:45 AM or 10:15 AM-11:00 AM.\n",
    "\n",
    "\n",
    "<img src=\"../figures/weighted tasks.PNG\" width=\"600px\"/>\n",
    "\n",
    "Reco recognized that the problem can be modeled as an acyclic directed graph(DAG), and the solution of the problem is the longest path in that graph.\n",
    "\n",
    "<img src=\"../figures/Constraint graph.PNG\" width=\"600px\"/>\n",
    "\n",
    "In general, the longest paths are hard problems, actually, they are NP-Complete. However, fortunately, the longest path in DAG is easy, they could be solved by dynamic programming (DP) algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T6_13.0_13.75',\n",
       " 'T5_12.0_12.5',\n",
       " 'T4_10.75_11.0',\n",
       " 'T3_9.5_10.75',\n",
       " 'T1_8.5_9.0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "tasks = [(\"T1\", 8.30, 9.30, 0.30, 3), \n",
    "         (\"T2\", 9.15, 10.15, 0.45, 4),\n",
    "         (\"T3\", 9.30, 10.45, 1.15, 2),\n",
    "         (\"T4\", 10.15, 11.30, 0.15, 1),\n",
    "         (\"T5\", 12.00, 13.30, 0.30, 5),\n",
    "         (\"T6\", 12.15, 13.45, 0.45, 2)]\n",
    "\n",
    "tasks = sorted(tasks, key=lambda x: x[2])\n",
    "\n",
    "def base_60_to_base_10(t):\n",
    "    t_hr, t_min = str(t).split(\".\")\n",
    "    t_hr = float(t_hr)\n",
    "    t_min = float(t_min)\n",
    "    if t_min < 10:\n",
    "        t_min = t_min * 10\n",
    "    t = t_hr + (t_min/60.0)\n",
    "    return t\n",
    "\n",
    "def base_10_to_base_60(t):\n",
    "    t_hr, t_min = str(t).split(\".\")\n",
    "    t_hr = float(t_hr)\n",
    "    t_min = float(t_min)\n",
    "    if t_min < 10:\n",
    "        t_min = t_min * 10\n",
    "    t = t_hr + (t_min/100.0 * 0.6)\n",
    "    return t\n",
    "\n",
    "\n",
    "def find_possible_slots(start_time, end_time, duration):\n",
    "    for i in range(int((end_time - start_time) / 0.25)):\n",
    "        end_time_ = start_time + i * 0.25 + duration\n",
    "        if end_time_ <= end_time:\n",
    "            yield (start_time + i * 0.25, start_time + i * 0.25 + duration, duration)\n",
    "            \n",
    "            \n",
    "def connect_tasks_to_successor(tasks, i):\n",
    "    #tasks that will start after i finish and start <= finish of connected to task\n",
    "    #we dont connect last task\n",
    "    if i >= len(tasks) - 1:\n",
    "        return\n",
    "    \n",
    "    to_connect = []\n",
    "    task = tasks[i]\n",
    "    max_successor_start = task[\"finish\"]\n",
    "    for task_ in tasks[i+1:]:\n",
    "        if task[\"task_group\"] == task_[\"task_group\"]:\n",
    "            continue\n",
    "        if task_[\"start\"] >= task[\"finish\"] and (task_[\"start\"] <= max_successor_start or len(to_connect) == 0):\n",
    "            to_connect += [task_[\"task\"]]\n",
    "            max_successor_start = max(task_[\"finish\"], max_successor_start)\n",
    "            \n",
    "    return to_connect\n",
    "\n",
    "\n",
    "tasks_ = []\n",
    "for task in tasks:\n",
    "    slots = list(find_possible_slots(base_60_to_base_10(task[1]), base_60_to_base_10(task[2]), base_60_to_base_10(task[3])))\n",
    "    for slot in slots:\n",
    "        tasks_ += [{\"task\": task[0] + \"_\" + str(slot[0]) + \"_\" + str(slot[1]), \"task_group\": task[0], \"start\": slot[0], \"finish\": slot[1], \"duration\": slot[2], \"weight\": task[4]}]\n",
    "tasks_  = sorted(tasks_, key=lambda x: x[\"finish\"])\n",
    "\n",
    "#build the DAG\n",
    "DAG = []\n",
    "for i in range(0, len(tasks_)):\n",
    "    task = {\"task\": tasks_[i][\"task\"], \"info\": tasks_[i], \"next_tasks\": connect_tasks_to_successor(tasks_, i)}\n",
    "    DAG += [task]\n",
    "    \n",
    "best_weight = defaultdict(float)\n",
    "best_from = defaultdict(str)\n",
    "weight = {task[\"task\"]: task[\"info\"][\"duration\"]  for task in DAG}\n",
    "\n",
    "for i in DAG:\n",
    "    if i[\"next_tasks\"] is not None:\n",
    "        for next_task in i[\"next_tasks\"]:\n",
    "            if weight[next_task] + best_weight[i[\"task\"]] > best_weight[next_task]:\n",
    "                best_weight[next_task] = weight[next_task] + best_weight[i[\"task\"]]\n",
    "                best_from[next_task] = i[\"task\"]\n",
    "                \n",
    "last_task = sorted(best_weight.items(), key=lambda i:i[1])[-1][0]\n",
    "path = [last_task]\n",
    "while best_from[last_task] != \"\":\n",
    "    path += [best_from[last_task]]\n",
    "    last_task = best_from[last_task]\n",
    "    \n",
    "path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 3: let's face it, no algorithm is enough!\n",
    "\n",
    "Great! reko is almost there, the DP algorithm collects x units of utility. Reco have one last riddle to solve, in reality, each call has a probabilistic output. For example, if he spends 45 Mins with the client 1 there is 85% probability to succeed and 15% to fail and gain nothing, in the other hand if he spends only 15 Mins the client will not feel comfortable and the probability reduces to 35% of success and 65% of failure. This introduces two problems, first: what does it mean to find an optimal solution when the output is probabilistic. And second, even if we could solve it, from where on plant earth we could get these probabilities! Reco took a large cup of coffee and went on deep thinking, after a couple of hours Reco recognized that the algorithm should mutually optimize for total value and learn the probabilities on the way. Does the combo of optimization and learning sound familiar to you? of course, this is what bandits do.\n",
    "\n",
    "\n",
    "> **_NOTE:_** it is common that constraints of real-world problems make the algorithm design a hard task. Instead, model the problem and let the solvers do the heavy lifting for you ;)\n",
    "\n",
    "* Issue 1: How to overcome the pathological case of our algorithm\n",
    "* Issue 2: How to account for the probabilistic outcome \n",
    "* Issue 3: How to solve the problem with missing info\n",
    "\n",
    "the dynamic programming worked well for this example, however, there are few problems with it: first, for cases of small meeting time with longer slot available, the algorithm may pic the same slot multiple times (as in example below), and second what if the client is providing multiple available slots in his calendar, the same client may be picked for multiple meetings in one day. Although you can modify your algorithm to avoid these cases it is most likely not a good idea. In the real world scenarios, the problem will be modified in various ways that make the algorithm design a hard task and you will need to revamp your algorithm over and over.\n",
    "\n",
    "For example, think about what will happen if you are asked to use the algorithm with a team of marketing agents instead of one, and what if each of them has different availability time and workload? these modifications will make the problem harder and most likely NP-Complete and there will not be a good algorithm that scale to more than a few marketing slots per calendar. In that case, to avoid being fired, you want to design an algorithm that results in good enough solutions instead of an optimal one.  \n",
    "\n",
    "Instead of working hard on the algorithm, we want to work hard on modeling the problem and use a tool that comes up with good solutions, even in case the problem is NP-Complete. This will allow us to save the algorithm development time and make iterative solutions by changing the objective and adding constraints to our problem. Fortunately, for a large portion of such a problem, there are optimization methods that could be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyomo\n",
    "# !pyomo install-extras\n",
    "#!conda install -y -c conda-forge pyomo.extras\n",
    "#!conda install -y -c conda-forge glpk\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdb\n",
    "import math\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Knapask problem\n",
    "To best demonistrate the idea lets take a simple example before going further. Suppose you are planning a trip and want to take some items with you, however, your car has limited capacity and you want to pick the items that are most valuable for you. suppose you have a hammer, wrench, screwdriver, towel. The weights and importance of these items are listed in table x. This problem is known as the knapsack problem and it is known to be an NP-Complete problem.\n",
    "\n",
    "> **_NOTE:_** NP-Complete problem does not mean problem is unsolvable. TODO clarify!\n",
    "\n",
    "To solve the problem we will use pyomo which is a great python package that wraps multiple optimizers and provide an elegant way of modeling optimization problems.\n",
    "\n",
    "First thing we define the data model, it includes the item, the importance, and the weight of each item. To model the problem we should define a few things:\n",
    "- **Optimization variable**, in this case, a boolean variable per items that indicate if it should be selected for the trip or not.\n",
    "- **Objective we are trying to optimize**, in this case, the sum of values of items that we can carry\n",
    "- **Constraints** that are imposed on our problem, here the sum of picked items wait are less than 14\n",
    "\n",
    "Fortunately, these constructs are available in pyomo and are intuitive to use. You can just define variables, objectives, and constraints and attach them to a model. After that, you just initiate a solver and voila, you have your answer!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Could not locate the 'glpsol' executable, which is required for\n",
      "    solver 'glpk'\n"
     ]
    },
    {
     "ename": "ApplicationError",
     "evalue": "No executable found for solver 'glpk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mApplicationError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-65691a6d756b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m#Voela !\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mresult_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pyomo\\opt\\base\\solvers.py\u001b[0m in \u001b[0;36msolve\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[1;34m\"\"\" Solve the problem \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavailable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexception_flag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m         \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;31m# If the inputs are models, then validate that they have been\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pyomo\\opt\\solver\\shellcmd.py\u001b[0m in \u001b[0;36mavailable\u001b[1;34m(self, exception_flag)\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mexception_flag\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"No executable found for solver '%s'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mApplicationError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mApplicationError\u001b[0m: No executable found for solver 'glpk'"
     ]
    }
   ],
   "source": [
    "from pyomo.environ import *\n",
    "import pyomo.environ as pe \n",
    "\n",
    "# the data\n",
    "A = ['hammer', 'wrench', 'screwdriver', 'towel']\n",
    "b = {'hammer':8, 'wrench':3, 'screwdriver':6, 'towel':11}\n",
    "w = {'hammer':5, 'wrench':7, 'screwdriver':4, 'towel':3}\n",
    "W_max = 14\n",
    "\n",
    "#the model \n",
    "model = ConcreteModel()\n",
    "\n",
    "# the variables\n",
    "model.x = Var( A, within=Binary )\n",
    "\n",
    "# the objective \n",
    "model.value = Objective(expr = sum( b[i]*model.x[i] for i in A), sense = maximize )\n",
    "\n",
    "# weights \n",
    "model.weight = Constraint(expr = sum( w[i]*model.x[i] for i in A) <= W_max )\n",
    "\n",
    "#solver \n",
    "opt = SolverFactory('glpk')\n",
    "\n",
    "#Voela !\n",
    "result_obj = opt.solve(model) \n",
    "model.x.get_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modifying the problem\n",
    "now let's say you decided that either hammer or wrench should be picked. No problems, you go the model, define a constraint and run again and that's it. You can see now that instead of focusing on the algorithm itself, you have room to focus on the problem and let pyomo do the heavy lifting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.c = Constraint(expr = sum(model.x[i] for i in [A[1], A[3]]) == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A sanity check baseline\n",
    "So how to know that the solution is good enough after all. A good idea is to build some baseline to compare with because we don't care about the perfect solution the baseline should be simple enough. in this example, let's say we pick the highest value fist until we don't have space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the solution of the baseline is wrench, hammer, and towel which sum up to 14 the same as ... (TODO find better weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scheduling as an optimization problem\n",
    "Now, let's return to our scheduling problem. We define the optimization problem as follows:\n",
    "\n",
    "- **Variables**: boolean variable for each possible slot to be picked or not.\n",
    "- **Objective**: maximize the sum of value from scheduled meetings\n",
    "- **Constraint**: sum(slots per client) <= 1 for each client (each client could be contacted at most once per day)\n",
    "- **Constraint**: Sum(slots) <= 1 for each overlap\n",
    "\n",
    "and pretty much that's it, now lets put it into code:\n",
    "\n",
    "**1. Generate sample problems**: instead of using fixed problem we generate sample problems for testing our algorithms. for each client, we generate 1-2 available times per day, each of these could randomly start between 8 and 14 and have a random duration of 15, 30, 45 or 60 mins. And finally, each available time is associated with some random weight.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_schedual(clients):\n",
    "    schedual = []\n",
    "    for client in clients:\n",
    "        num_slots = random.randint(1, 2)\n",
    "        for i in range(num_slots):\n",
    "            start = float(random.randint(8, 14)) + random.randint(0, 4) * 0.25\n",
    "            duration = 0.25 * random.randint(1, 4)\n",
    "            end = start + duration\n",
    "            weight = random.randint(1, 5)\n",
    "            schedual += [[client, start, end, duration, weight]]\n",
    "    return schedual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Enumerate slots** each available time per client may have different solts, we enumerate them all and store them into a pandas data frame for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# tasks = [[\"T1\", 08.50, 09.50, 1.00, 3], \n",
    "#          [\"T2\", 09.25, 10.00, 0.75, 4],\n",
    "#          [\"T3\", 09.50, 10.75, 0.50, 2],\n",
    "#          [\"T4\", 10.25, 11.50, 0.25, 1],\n",
    "#          [\"T5\", 12.00, 13.50, 0.75, 1],\n",
    "#          [\"T6\", 12.25, 13.75, 0.75, 2],\n",
    "#          [\"T1\", 12.00, 13.50, 1.00, 3]]\n",
    "\n",
    "tasks = generate_schedual([\"T1\", \"T2\", \"T3\", \"T4\", \"T5\", \"T6\"])\n",
    "def find_possible_slots(start_time, end_time, duration):\n",
    "    for i in range(int((end_time - start_time) / 0.25)):\n",
    "        end_time_ = start_time + i * 0.25 + duration\n",
    "        if end_time_ <= end_time:\n",
    "            yield (start_time + i * 0.25, start_time + i * 0.25 + duration, duration)\n",
    "\n",
    "def task_id(task, slot):\n",
    "    return {\"task\": task[0] + \"_\" + str(slot[0]) + \"_\" + str(slot[1]), \n",
    "            \"task_group\": task[0], \n",
    "            \"start\": slot[0], \n",
    "            \"finish\": slot[1], \n",
    "            \"duration\": slot[2], \n",
    "            \"weight\": task[4]}\n",
    "\n",
    "def compute_possible_tasks(tasks):\n",
    "    tasks_ = []\n",
    "    for task in tasks:\n",
    "        slots = find_possible_slots(float(task[1]), float(task[2]), float(task[3]))\n",
    "        for slot in slots:\n",
    "            tasks_ += [task_id(task, slot)]\n",
    "    tasks_  = sorted(tasks_, key=lambda x: x[\"finish\"])\n",
    "    return pd.DataFrame(tasks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Find overlaps** We find overlapped tasks using pandas, please not this implementation is not efficient however we use it here for illustration purposes, in production you need to consider using better data structure like segment tree to find overlapping tasks efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_task_overlaps(possible_tasks):\n",
    "    overlapping_tasks = {}\n",
    "    for task in possible_tasks.task.unique():\n",
    "        start, finish = possible_tasks[possible_tasks.task == task].iloc[0][[\"start\", \"finish\"]].values\n",
    "        overlapping_tasks_ = possible_tasks[(possible_tasks.start >= start) & (possible_tasks.start < finish)]\n",
    "        overlapping_tasks_ = list(overlapping_tasks_.task.unique())\n",
    "        if len(overlapping_tasks_) > 1:\n",
    "            overlapping_tasks[task] = overlapping_tasks_\n",
    "    return overlapping_tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Optimize** we define the optimization problem. (break it down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedual_tasks(tasks):\n",
    "    model = ConcreteModel()\n",
    "\n",
    "    #data\n",
    "    possible_tasks = compute_possible_tasks(tasks)\n",
    "    tasks = possible_tasks.task.values\n",
    "    w = {r.task: r.weight for _, r in possible_tasks[possible_tasks.task == tasks].iterrows()}\n",
    "\n",
    "    #constarint data\n",
    "    overlapping_tasks = find_task_overlaps(possible_tasks)\n",
    "    task_groups = possible_tasks[\"task_group\"].unique()\n",
    "\n",
    "    #variables\n",
    "    model.x = Var(tasks, within=Binary )\n",
    "\n",
    "    #objective\n",
    "    model.value = Objective(expr = sum(w[i]*model.x[i] for i in tasks), sense = maximize )\n",
    "\n",
    "    #constraints\n",
    "    @model.Constraint(task_groups)\n",
    "    def one_each_group(m, tg):\n",
    "        return sum(m.x[task] for task in possible_tasks[possible_tasks[\"task_group\"] == tg][\"task\"].unique()) <= 1\n",
    "\n",
    "    @model.Constraint(overlapping_tasks.keys())\n",
    "    def one_each_overlap(m, t):\n",
    "        return sum(m.x[task] for task in overlapping_tasks[t]) <= 1\n",
    "\n",
    "    #solve\n",
    "    opt = SolverFactory('glpk')\n",
    "    result_obj = opt.solve(model)\n",
    "    selected = [k for k, v in model.x.get_values().items() if v == 1]\n",
    "    \n",
    "    #formate resutls\n",
    "    results = (possible_tasks\n",
    "          .loc[possible_tasks.task.isin(selected)]\n",
    "          .sort_values(by=['start'])\n",
    "          .set_index(\"task_group\")\n",
    "          [[\"start\", \"finish\", \"duration\", \"weight\"]])\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "results = schedual_tasks(tasks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>finish</th>\n",
       "      <th>duration</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T6</th>\n",
       "      <td>10.00</td>\n",
       "      <td>10.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T4</th>\n",
       "      <td>10.25</td>\n",
       "      <td>10.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1</th>\n",
       "      <td>11.75</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T3</th>\n",
       "      <td>12.75</td>\n",
       "      <td>13.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T2</th>\n",
       "      <td>13.25</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T5</th>\n",
       "      <td>14.25</td>\n",
       "      <td>14.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            start  finish  duration  weight\n",
       "task_group                                 \n",
       "T6          10.00   10.25      0.25       5\n",
       "T4          10.25   10.50      0.25       1\n",
       "T1          11.75   12.00      0.25       3\n",
       "T3          12.75   13.25      0.50       5\n",
       "T2          13.25   14.00      0.75       3\n",
       "T5          14.25   14.75      0.50       3"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.weight.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Baseline sanity check** to verify that our solution is working fine, we set a greedy algorithm that takes the most valuable tasks first and eliminates all conflicting tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_possible_tasks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-174735a7f8d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpossible_tasks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossible_tasks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mschedual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0msolve_by_elemination\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-174735a7f8d3>\u001b[0m in \u001b[0;36msolve_by_elemination\u001b[1;34m(tasks)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msolve_by_elemination\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mschedual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpossible_tasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_possible_tasks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mpossible_tasks_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpossible_tasks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'compute_possible_tasks' is not defined"
     ]
    }
   ],
   "source": [
    "def solve_by_elemination(tasks):\n",
    "    schedual = []\n",
    "    possible_tasks = compute_possible_tasks(tasks)\n",
    "    possible_tasks_ = possible_tasks.copy().sort_values(by=['weight'], ascending=False)\n",
    "    for i in range(100):\n",
    "        try:\n",
    "            task, task_group, start, finish = possible_tasks_.iloc[i][[\"task\", \"task_group\", \"start\", \"finish\"]]\n",
    "            possible_tasks_ = possible_tasks_[~((possible_tasks_.start >= start) \n",
    "                                                & (possible_tasks_.start < finish) \n",
    "                                                & ((possible_tasks_.task != task)))]\n",
    "            possible_tasks_ = possible_tasks_[~((possible_tasks_.finish > start) \n",
    "                                                & (possible_tasks_.finish <= finish) \n",
    "                                                & ((possible_tasks_.task != task)))]\n",
    "            possible_tasks_ = possible_tasks_[(possible_tasks_.task_group != task_group) \n",
    "                                              | (possible_tasks_.task == task ) ]\n",
    "            schedual += [task]\n",
    "        except:\n",
    "            break\n",
    "    return possible_tasks[possible_tasks.task.isin(schedual)]\n",
    "\n",
    "solve_by_elemination(tasks).weight.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we see that our optimization is surpassing the baseline and the results make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 4: We don't know the weights\n",
    "\n",
    "Looking back to what we have right now, we have clients that we want to meet during a day, each client provide his free time slots, and each meeting have specific duration and importance associated with it, your job is to schedule the meetings to maximize the importance you get from the meetings. You have realized the problem complexity, switch gears from building a complex algorithm to build a simple model and use pyomo optimization library to solve it, so far so good.\n",
    "\n",
    "Now, you can imagine that the importance of each client is not pre defined, actually, we learned it on the way. Is it possible to extend our algorithm to optimize the schedule and learn the importance at the same time?. To answer this question, let's focus on the learning aspect. Imagine that you are traveling to a new country, you want to get some lunch and you find 2 restaurants nearby and you want to know which one to choose. Your measure from quality is on a scale from 0 to 1, where 0 means you don't like the food at all and 1 for perfect food. If you tried one restaurant for 10 times, you can compute the mean and standard deviation and form a confidence interval of the food quality at that restaurant. Comparing two restaurants is somehow tricky. If one restaurant got a 70% score and another get 75%, you could expect that the second is a better one, however it could be due to random reason. To establish a safe decision, you could use statistical procedures like T-Test or ANOVA to test if the difference is statistically significant or not.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T-Test/ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While with the T-test it is pretty much safe to decide which restaurant is the best choice, you will need to try them all n times to draw the conclusion. That is simply not how we will solve it as humans, we don't try bad restaurants a hundred times to establish statistical significance! Instead, people will try restaurants at random and come back to the best ones they found so far, sometimes they will explore new options. This key in this method is to balance the exploration of new restaurants and the exploitation of the best restaurants. The value you loose due to exploring none optimal choices is called regret, and you basically want to minimize your regret of going to bad restaurants. Fortunately, the exploration vs. exploitation problem known as Multi-Arm Bandit MAB (TODO: add info in a side box) is well studied one, and in fact, there are provably optimal strategies to solve it. In general, we could rely on the principle of optimism in the face of uncertainty (TODO: add infobox), the idea is to choose the best know choices when we are not certain.\n",
    "\n",
    "TODO: explain the UCB1 algorithm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UCB1 and regret plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going from restaurants to optimization algorithms, we want to utilize the same principle optimism in the face of uncertainty. To make it possible it is better to model the optimization algorithm like an agent that interacts with some environment to learn about the problem and find an optimal solution. Our model has the following components:\n",
    "\n",
    "- **Problem**: This encapsulates the objective, the constraints, the structure of the problem and all other info except for the problem wights.\n",
    "- **Parameters**: encapsulate the weight of the problem \n",
    "- **Solver**: the optimizer we use to solve the problem \n",
    "- **Oracle**: the environment sensor that will tell us the weights of the solution\n",
    "- **Agent**: This takes the problem, parameters, and a solver to solve the problem and then use the oracle to observe the solution quality.\n",
    "\n",
    "#TODO draw a schematic of the env, infobox about AI agent architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Oracle:\n",
    "    def observe(self, problem, solution):\n",
    "        pass\n",
    "        \n",
    "class Solver:\n",
    "    def solve(self, problem, weights):\n",
    "        pass\n",
    "    \n",
    "class Problem:\n",
    "    pass\n",
    "\n",
    "class ProblemModel:\n",
    "    def get_all_weights(self):\n",
    "        pass\n",
    "    \n",
    "    def set_weights(self, weights):\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our scheduling example, the problem will hold the meetings informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskSchedualingProblem(Problem):\n",
    "    def __init__(self, tasks):\n",
    "        self.tasks = tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters will store the weights of each possible meeting, note that all possible tasks belong to the parent task have the same weight. For convenience, we set two modes to initialize the weights random and know waits. Know weights will be used to solve the problem as we know it, while random initial weights will be used whenever are in bandit mode. (TODO: rephrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskSchedualingProblemModel(ProblemModel):\n",
    "    def __init__(self, tasks, weights_known=False):\n",
    "        if weights_known:\n",
    "            self.weights = dict(compute_possible_tasks(tasks)[[\"task_group\", \"weight\"]].drop_duplicates().values)\n",
    "        else:\n",
    "            self.weights = {i: random.random() for i in compute_possible_tasks(tasks)[\"task_group\"].drop_duplicates().values}\n",
    "        self.arms = self.weights.keys()  \n",
    "        \n",
    "    def get_all_weights(self):\n",
    "        return self.weights\n",
    "    \n",
    "    def set_weights(self, weights):\n",
    "        for k, v in weights.items():\n",
    "            self.weights[k] = v\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solver will simply call the schedule tasks function we defined before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskSchedualingSolver(Solver):\n",
    "    def __init__(self):\n",
    "        pass \n",
    "    \n",
    "    def solve(self, problem, weights):\n",
    "        tasks = [task[:4] + [weights[task[0]]] for task in problem.tasks]\n",
    "        return schedual_tasks(tasks).index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Oracle models our environment, depending on the nature of the environment the observations could be true values or noisy readings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskSchedualingOracle(Oracle):\n",
    "    def __init__(self, tasks, noise_factor=3.0):\n",
    "        self.weights = dict(compute_possible_tasks(tasks)[[\"task_group\", \"weight\"]].drop_duplicates().values)\n",
    "        self.arms = self.weights.keys()  \n",
    "        self.noise_factor = noise_factor\n",
    "        \n",
    "    def get_weight(self, x, noisy=False):\n",
    "        if noisy:\n",
    "            return self.weights[x] + (random.random() - 0.5) * self.noise_factor\n",
    "        else:\n",
    "            return self.weights[x]\n",
    "        \n",
    "    def observe(self, problem, solution, noisy=False):\n",
    "        return [self.get_weight(x, noisy=noisy) for x in solution]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 1545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem = TaskSchedualingProblem(tasks)\n",
    "problem_model = TaskSchedualingProblemModel(tasks, weights_known=True)\n",
    "oracle = TaskSchedualingOracle(tasks, noise_factor=5)\n",
    "solver = TaskSchedualingSolver()\n",
    "sln = solver.solve(problem, problem_model.get_all_weights())\n",
    "sum(oracle.observe(problem, sln, noisy=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 1546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_model_uncertain = TaskSchedualingProblemModel(tasks, weights_known=False)\n",
    "sln = solver.solve(problem, problem_model_uncertain.get_all_weights())\n",
    "sum(oracle.observe(problem, sln, noisy=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombUcb1:\n",
    "    def __init__(self, problem, problem_model, solver, oracle, mode='Max'):\n",
    "        self.problem = problem\n",
    "        self.solver = solver\n",
    "        self.oracle = oracle\n",
    "        self.arms = problem_model.arms\n",
    "        self.mode = mode\n",
    "        self.init_algorithm()\n",
    "\n",
    "    def init_algorithm(self):\n",
    "        uu = {i: 0.0 for i in self.arms}\n",
    "        w = {i: 0.0 for i in self.arms}\n",
    "        t = 0\n",
    "        for arm in uu.keys():\n",
    "            if self.mode == 'Max':\n",
    "                uu[arm] = 1.0\n",
    "            elif self.mode == 'Min':\n",
    "                uu[arm] = 0.0\n",
    "            else:\n",
    "                raise Exception('Mode is only Max or Min')\n",
    "        solution_exists = True\n",
    "\n",
    "        while ((self.mode == 'Min' and np.min(list(uu.values())) == 0)\n",
    "                                        or (self.mode == 'Max' and np.max(list(uu.values())) == 1.0)):\n",
    "            At = self.solver.solve(self.problem, uu)\n",
    "            if At is None:\n",
    "                break\n",
    "            AtW = self.oracle.observe(self.problem, At, noisy=True)\n",
    "\n",
    "            for idx, e in enumerate(At):\n",
    "                w[e] = AtW[idx]\n",
    "                if self.mode == 'Max':\n",
    "                    uu[e] = 0.0\n",
    "                elif self.mode == 'Min':\n",
    "                    uu[e] = 1.0\n",
    "                else:\n",
    "                    raise Exception('Mode is only Max or Min')\n",
    "            t += 1\n",
    "        self.weights = w\n",
    "        self.time_steps = {i: 1.0 for i in w.keys()}\n",
    "        self.t = t\n",
    "\n",
    "    def bandit_iter(self):\n",
    "        weights = self.weights\n",
    "        time_steps = self.time_steps\n",
    "        t = self.t\n",
    "        if self.mode == 'Max':\n",
    "            u_ucb = {i: min(weights[i] + np.sqrt(1.5 * np.log(t)/time_steps[i]), 1.0) for i in weights.keys()}\n",
    "        elif self.mode == 'Min':\n",
    "            u_ucb = {i: max(weights[i] - np.sqrt(1.5 * np.log(t)/time_steps[i]), 0) for i in weights.keys()}\n",
    "        else:\n",
    "            raise Exception('Mode is only Max or Min')\n",
    "        At = self.solver.solve(self.problem, u_ucb)\n",
    "        wAt = self.oracle.observe(self.problem, At)\n",
    "        for idx, e in enumerate(At):\n",
    "            weights[e] = (time_steps[e] * weights[e] + wAt[idx]) / (time_steps[e] + 1)\n",
    "            time_steps[e] += 1\n",
    "        t += 1\n",
    "        self.time_steps = time_steps\n",
    "        self.weights = weights\n",
    "        self.t = t\n",
    "\n",
    "    def solve(self):\n",
    "        weights = self.weights\n",
    "        u_ucb = weights\n",
    "        return self.solver.solve(self.problem, u_ucb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1547,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "b = CombUcb1(problem=problem, problem_model=problem_model_uncertain, solver=solver, oracle=oracle, mode='Max')\n",
    "\n",
    "for i in range(5):\n",
    "    print (i)\n",
    "    b.bandit_iter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 1548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sln = solver.solve(problem, b.weights)\n",
    "sum(oracle.observe(problem, sln, noisy=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not only scheduling\n",
    "wait, but we can also solve problems without knowing the parametric! What about other problems?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Knapsack with unknown weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shortest path with unknown weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend to a team of phone marketers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1549,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents_workload = (\"Alex\", \"Jennifer\", \"Andrew\", \"DeAnna\", \"Jesse\")\n",
    "\n",
    "clients = (\n",
    "    \"Trista\", \"Meredith\", \"Aaron\", \"Bob\", \"Jillian\",\n",
    "    \"Ali\", \"Ashley\", \"Emily\", \"Desiree\", \"Byron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1550,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "def score(agent, client):\n",
    "    try:\n",
    "        s = 1 / (1 + math.exp(-np.dot(agents_v[agent], clients_v[client])))\n",
    "    except:\n",
    "        print (np.dot(agents_v[agent], clients_v[client]))\n",
    "        return random.random()\n",
    "    return s\n",
    "    \n",
    "def generate_matching_problem(agents, clients):\n",
    "    num_samples = len(agents) + len(clients)\n",
    "    samples = sklearn.datasets.make_swiss_roll(num_samples, noise=3, random_state=0)[0]\n",
    "    random.shuffle(samples)\n",
    "    clients_v = {clients[i]: samples[i] for i in range(len(clients))}\n",
    "    agents_v = {agents[i]: samples[i] for i in range(len(agents))}\n",
    "    match_scores = dict(\n",
    "        ((agent, client), score(agent, client))\n",
    "        for agent in agents_workloads\n",
    "        for client in clients)\n",
    "\n",
    "    client_time = {client: random.randint(1, 4) for client in clients}\n",
    "    agents_workload = {agent: random.randint(2, 5) for agent in agents}\n",
    "    \n",
    "    return match_scores, client_time, agents_workload, clients_v, agents_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1551,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_matching(match_scores, client_time, agents_workload):\n",
    "    agents = agents_workloads.keys()\n",
    "    clients = client_time.keys()\n",
    "    \n",
    "    model = pe.ConcreteModel()\n",
    "    model.agents = agents_workloads.keys()\n",
    "    model.clients = clients\n",
    "    model.match_scores = match_scores\n",
    "    model.agents_workload = agents_workload\n",
    "\n",
    "    model.assignments = pe.Var(match_scores.keys(), domain=pe.Binary)\n",
    "    model.objective = pe.Objective(\n",
    "            expr=pe.summation(model.match_scores, model.assignments),\n",
    "            sense=pe.maximize)\n",
    "\n",
    "    @model.Constraint(model.agents)\n",
    "    def respect_workload(model, agent):\n",
    "        return sum(model.assignments[agent, client] * client_time[client] for client in model.clients) <= model.agents_workload[agent]\n",
    "\n",
    "    @model.Constraint(model.clients)\n",
    "    def one_agent_per_client(model, client):\n",
    "        return sum(model.assignments[agent, client] for agent in model.agents) <= 1\n",
    "\n",
    "\n",
    "    solver = pe.SolverFactory(\"glpk\")\n",
    "    solver.solve(model)\n",
    "    sln = [k for k, v in model.assignments.get_values().items() if v == 1.0]\n",
    "    return sln, sum(match_scores[i] for i in sln)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1552,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_matching_greedy(match_scores, client_time, agents_workload):\n",
    "    agents = agents_workloads.keys()\n",
    "    clients = client_time.keys()\n",
    "    matching = sorted(match_scores.items(), key=lambda x: -x[1])\n",
    "    clients_indicator = {client: 0 for client in clients}\n",
    "    agents_workload_ = agents_workload.copy()\n",
    "    sln = []\n",
    "    for (agent, client), score in matching:\n",
    "        if clients_indicator[client] == 0 and agents_workload_[agent] >= client_time[client]:\n",
    "            clients_indicator[client] = 1\n",
    "            agents_workload_[agent] -= client_time[client]\n",
    "            sln += [(agent, client)]\n",
    "    return sln, sum([match_scores[i] for i in sln])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1553,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_scores, client_time, agents_workload, clients_v, agents_v = generate_matching_problem(agents, clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('DeAnna', 'Meredith'),\n",
       "  ('Andrew', 'Ashley'),\n",
       "  ('Jesse', 'Jillian'),\n",
       "  ('DeAnna', 'Emily'),\n",
       "  ('Jesse', 'Byron'),\n",
       "  ('Jennifer', 'Bob'),\n",
       "  ('Alex', 'Trista')],\n",
       " 7.0)"
      ]
     },
     "execution_count": 1554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve_matching(match_scores, client_time, agents_workload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('Alex', 'Trista'),\n",
       "  ('Jennifer', 'Bob'),\n",
       "  ('Andrew', 'Meredith'),\n",
       "  ('DeAnna', 'Aaron'),\n",
       "  ('DeAnna', 'Jillian'),\n",
       "  ('Jesse', 'Ashley')],\n",
       " 6.0)"
      ]
     },
     "execution_count": 1555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve_matching_greedy(match_scores, client_time, agents_workload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1556,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the matching optimization problem\n",
    "class MatchingProblem(Problem):\n",
    "    def __init__(self, match_scores, client_time, agents_workload, agents_v, clients_v):\n",
    "        self.match_scores = match_scores\n",
    "        self.agents_workload = agents_workload\n",
    "        self.client_time = client_time\n",
    "        self.features = {(agent, client): np.hstack([agents_v[agent], clients_v[client]]) \n",
    "                         for agent, client in match_scores.keys()}\n",
    "\n",
    "\n",
    "class MatchingProblemModel(ProblemModel):\n",
    "    def __init__(self, match_scores, weights_known=False):\n",
    "        if weights_known:\n",
    "            self.weights = match_scores.copy()\n",
    "        else:\n",
    "            self.weights = {i: random.random() for i in match_scores.keys()}\n",
    "        self.arms = self.weights.keys()  \n",
    "        \n",
    "    def get_all_weights(self):\n",
    "        return self.weights\n",
    "    \n",
    "    def set_weights(self, weights):\n",
    "        for k, v in weights.items():\n",
    "            self.weights[k] = v\n",
    "    \n",
    "\n",
    "class MatchingSolver(Solver):\n",
    "    def __init__(self):\n",
    "        pass \n",
    "    \n",
    "    def solve(self, problem, weights):\n",
    "        return solve_matching(weights, problem.client_time, problem.agents_workload)\n",
    "        \n",
    "        \n",
    "class MatchingOracle(Oracle):\n",
    "    def __init__(self, match_scores, noise_factor=3.0):\n",
    "        self.weights = match_scores.copy()\n",
    "        self.arms = self.weights.keys()  \n",
    "        self.noise_factor = noise_factor\n",
    "        \n",
    "    def get_weight(self, x, noisy=False):\n",
    "        if noisy:\n",
    "            return self.weights[x] + (random.random() - 0.5) * self.noise_factor\n",
    "        else:\n",
    "            return self.weights[x]\n",
    "        \n",
    "    def observe(self, problem, solution, noisy=True):\n",
    "        return [self.get_weight(x, noisy=noisy) for x in solution]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1590,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CombTS\n",
    "class CombLinTs:\n",
    "    def __init__(self, problem, p_lambda, p_sigma, solver, oracle):\n",
    "        self.d = np.array(list(problem.features.values())).shape[1]\n",
    "        self.p_lambda = p_lambda\n",
    "        self.p_sigma = p_sigma\n",
    "        self.sigma = (p_lambda ** 2) * np.eye(self.d)\n",
    "        self.theta = np.zeros(self.d)\n",
    "        self.solver = solver\n",
    "        self.oracle = oracle\n",
    "        \n",
    "    def sample_theta(self):\n",
    "        return np.random.multivariate_normal(self.theta, self.sigma)\n",
    "    \n",
    "    def update_params(self, wAt):\n",
    "        theta = self.theta\n",
    "        sigma = self.sigma\n",
    "        \n",
    "        n = len(wAt)\n",
    "        \n",
    "        for k, v in wAt.items():\n",
    "            f_vec = np.expand_dims(problem.features[k], axis=1)\n",
    "            t1 = np.matmul(sigma, np.matmul(f_vec, f_vec.T))\n",
    "            t2 = np.matmul(f_vec.T, np.matmul(sigma, f_vec)) + self.p_sigma ** 2\n",
    "            t3 = np.matmul(sigma, f_vec)\n",
    "            t4 = np.matmul(np.matmul(f_vec.T, sigma), f_vec) + self.p_sigma ** 2\n",
    "            theta = np.matmul((np.eye(sigma.shape[0]) - t1 / t2), theta) + \\\n",
    "                        np.squeeze(t3 / t4) * wAt[k]\n",
    "\n",
    "            t1 = np.matmul(np.matmul(sigma, np.matmul(f_vec, f_vec.T)), sigma)\n",
    "            t2 = np.matmul(np.matmul(f_vec.T, sigma), f_vec) + self.p_sigma ** 2\n",
    "            sigma = sigma - t1/t2\n",
    "    \n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "            \n",
    "    def bandit_iter(self, problem):\n",
    "        theta = self.sample_theta()\n",
    "        At, _ = self.solver.solve(problem, {k: np.dot(v, theta) for k, v in problem.features.items()})\n",
    "        wAt = self.oracle.observe(problem, At, noisy=True)\n",
    "        wAt = dict(zip(At, wAt))\n",
    "        self.update_params(wAt)\n",
    "        \n",
    "    def solve(self, problem):\n",
    "        theta = self.sample_theta()\n",
    "        sln, _ = self.solver.solve(problem, {k: np.dot(v, theta) for k, v in problem.features.items()})\n",
    "        return sln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1634,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.00008340099822"
      ]
     },
     "execution_count": 1634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_scores, client_time, agents_workload, clients_v, agents_v = generate_matching_problem(agents, clients)\n",
    "problem = MatchingProblem(match_scores, client_time, agents_workload, agents_v, clients_v)\n",
    "problem_model = MatchingProblemModel(match_scores, weights_known=False)\n",
    "oracle = MatchingOracle(match_scores, noise_factor=2)\n",
    "solver = MatchingSolver()\n",
    "sln, w = solver.solve(problem, problem_model.get_all_weights())\n",
    "np.sum(oracle.observe(problem, At, noisy=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1635,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 1635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_model = MatchingProblemModel(match_scores, weights_known=True)\n",
    "sln, w = solver.solve(problem, problem_model.get_all_weights())\n",
    "np.sum(oracle.observe(problem, sln, noisy=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "8.0\n",
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "8.0\n",
      "8.0\n",
      "8.0\n"
     ]
    }
   ],
   "source": [
    "p_lambda = 10.\n",
    "p_sigma = 0.1\n",
    "features_dim =  10\n",
    "bandit = CombLinTs(p_lambda=p_lambda,\n",
    "                     p_sigma=p_sigma, problem=problem, solver=solver, oracle=oracle)\n",
    "\n",
    "for i in range(100):\n",
    "    bandit.bandit_iter(problem=problem)\n",
    "    if i % 10 == 0:\n",
    "        At = bandit.solve(problem)\n",
    "        print (np.sum(oracle.observe(problem, At, noisy=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* scale up all pairs \n",
    "* We assumed all weight is random, what if they are normal with different means and variances\n",
    "* Empirical Bayes for new joiners \n",
    "* Extend to team\n",
    "* Spending more time is useful\n",
    "* Streamline with Tensorflow probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: the bandit example\n",
    "# TODO: drwa gunt chart\n",
    "# TODO: shortest path \n",
    "# TODO: Knapsack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to do both selection and scheduling, learn the importance of each client, start from reasonable wights for faster exploration or add more cool features. Very well, we will go through after we introduce some cool tools. For the time being, let's sharpen our skills by solving 2 other problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The dauntless conclusion**: *Be a modeling super star, dont fear missing info!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliography (Text style like in introduction to algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
