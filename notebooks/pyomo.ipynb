{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyomo\n",
    "# !pyomo install-extras\n",
    "#!conda install -y -c conda-forge pyomo.extras\n",
    "#!conda install -y -c conda-forge glpk\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdb\n",
    "import math\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the dynamic programming worked well for this example, however there are few problems with it: first for cases of small meeting time with longer slot available, the algorithm may pic the same slot multiple times (as in example below), and second what if the client is providing multiple available solts in his calender, the same client may be picked for maultiple meetings in one day. Although you can modefy your algorithm to avoid these cases it is most likely not a good idea. In real world schenarios the problem will be modified in various ways that make the algorithm desing a hard task and you will need to revamp your algorithm over and over.\n",
    "\n",
    "For example, think what will happen if you are asked to use the algorithm wiht a team of marketing agents instead of one, and what if each of them have differnt availability time and workload? these modifications wlll makehte problem harder and most likely NP-Complete and there will not be a good algorithm that scale to more than few marketing slots per calender. In that case to avoid being fired, you want to desing an algorithm that result in good enough solutions instead of optimal one.  \n",
    "\n",
    "Instead of working hard on the algorithm, we want to work hard on modeling the problem and use a tool that come up with good solutions, even in case the problem is NP-Complete. This will allow us to save the algorith development time and make iterative solutions by changing the objective and adding constraints to our problem. Fortunatly, for large protion of such problem, there are optmization methods that could be used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Knapask problem\n",
    "To best demonistrate the idea lets take a simple example before going further. Suppose you are going into tip and want to take some items with you, however your car have limited capacity and you want to pic the itmes that are most valiable for you. suppose you have hammer, wrench, screwdriver, towel. The weights and importance of these items are listed in table x. This problem known as knapsak problem is NP-Complete problem.\n",
    "\n",
    "To solve the proble we will use pyomo which is a great python package that wrap multiple optimizers and provide elegent way of modeling optimiztion problems.\n",
    "\n",
    "First thing we define the data model, it includ the iteam, the importance and the wait. To model the problem we should define few things:\n",
    "- **Optimization variable**, in this case a boolean variable per items taht indicate if it should be selected for the trip or not.\n",
    "- **Objective we are trying to optimize**, in this case the sum of values of items that we can carry\n",
    "- **Constraints** that are imposed to our problem, here the sum of picked items wait are less than 14\n",
    "\n",
    "Fortunatly, these constructes are available in pyomo and are intutive to use. You can just define variables, objectives and constraints and attach them to a model. After that you just initiate an solver and voela, you have your answer!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'screwdriver': 1.0, 'towel': 1.0, 'wrench': 0.0, 'hammer': 1.0}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyomo.environ import *\n",
    "import pyomo.environ as pe \n",
    "\n",
    "# the data\n",
    "A = ['hammer', 'wrench', 'screwdriver', 'towel']\n",
    "b = {'hammer':8, 'wrench':3, 'screwdriver':6, 'towel':11}\n",
    "w = {'hammer':5, 'wrench':7, 'screwdriver':4, 'towel':3}\n",
    "W_max = 14\n",
    "\n",
    "#the model \n",
    "model = ConcreteModel()\n",
    "\n",
    "# the variables\n",
    "model.x = Var( A, within=Binary )\n",
    "\n",
    "# the objective \n",
    "model.value = Objective(expr = sum( b[i]*model.x[i] for i in A), sense = maximize )\n",
    "\n",
    "# weights \n",
    "model.weight = Constraint(expr = sum( w[i]*model.x[i] for i in A) <= W_max )\n",
    "\n",
    "#solver \n",
    "opt = SolverFactory('glpk')\n",
    "\n",
    "#Voela !\n",
    "result_obj = opt.solve(model) \n",
    "model.x.get_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modifing the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now lets say you dicided that either hammer or wrench should be picked. No problems, you go the the model, define a constraint and run again and thats it. You can see now that instead of foucsing on the algorithm itself, you have room to focus on the problme and let pyomo do the heavy lifting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.c = Constraint(expr = sum(model.x[i] for i in [A[1], A[3]]) == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A baseline for sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how to know that the solution is good enough after all. A good idea is to build some baseline to compare with, because we dont care about perfect solution the base line should be simple enough. in this example, lets say we pic the highest value fist until we dont have space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the solution of the base line is wrench, hammer and towel which sum up to 14 same as ... (find better weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Schedualing as an optmization problme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets return to our schedualling problem. We define the optmization problem as follows:\n",
    "\n",
    "- **Variables**: boolean varaible for each possible slot to be picked or not.\n",
    "- **Objective**: maximize the sum of value from schedualed meetings\n",
    "- **Constraint**: sum(slots per client) <= 1 for each client (each client could be contacted at most once per day)\n",
    "- **Constraint**: Sum(slots) <= 1 for each overlap\n",
    "\n",
    "and prety much thats it, now lets put it into code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Generate smaple problems**: instead of using fixed problme we generate sample problmes for tesing our algorithms. for each client we generate 1-2 available times per day, each of these could randomly start between 8 and 14 and have random duration of 15, 30, 45 or 60 mins. And finally, each available time is associated with some random wieght."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_schedual(clients):\n",
    "    schedual = []\n",
    "    for client in clients:\n",
    "        num_slots = random.randint(1, 2)\n",
    "        for i in range(num_slots):\n",
    "            start = float(random.randint(8, 14)) + random.randint(0, 4) * 0.25\n",
    "            duration = 0.25 * random.randint(1, 4)\n",
    "            end = start + duration\n",
    "            weight = random.randint(1, 5)\n",
    "            schedual += [[client, start, end, duration, weight]]\n",
    "    return schedual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Enumerate slots** each available time per client may have different solts, we enumerate thme all and store them into a pandas dataframe for conviniance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# tasks = [[\"T1\", 08.50, 09.50, 1.00, 3], \n",
    "#          [\"T2\", 09.25, 10.00, 0.75, 4],\n",
    "#          [\"T3\", 09.50, 10.75, 0.50, 2],\n",
    "#          [\"T4\", 10.25, 11.50, 0.25, 1],\n",
    "#          [\"T5\", 12.00, 13.50, 0.75, 1],\n",
    "#          [\"T6\", 12.25, 13.75, 0.75, 2],\n",
    "#          [\"T1\", 12.00, 13.50, 1.00, 3]]\n",
    "\n",
    "tasks = generate_schedual([\"T1\", \"T2\", \"T3\", \"T4\", \"T5\", \"T6\"])\n",
    "def find_possible_slots(start_time, end_time, duration):\n",
    "    for i in range(int((end_time - start_time) / 0.25)):\n",
    "        end_time_ = start_time + i * 0.25 + duration\n",
    "        if end_time_ <= end_time:\n",
    "            yield (start_time + i * 0.25, start_time + i * 0.25 + duration, duration)\n",
    "\n",
    "def task_id(task, slot):\n",
    "    return {\"task\": task[0] + \"_\" + str(slot[0]) + \"_\" + str(slot[1]), \n",
    "            \"task_group\": task[0], \n",
    "            \"start\": slot[0], \n",
    "            \"finish\": slot[1], \n",
    "            \"duration\": slot[2], \n",
    "            \"weight\": task[4]}\n",
    "\n",
    "def compute_possible_tasks(tasks):\n",
    "    tasks_ = []\n",
    "    for task in tasks:\n",
    "        slots = find_possible_slots(float(task[1]), float(task[2]), float(task[3]))\n",
    "        for slot in slots:\n",
    "            tasks_ += [task_id(task, slot)]\n",
    "    tasks_  = sorted(tasks_, key=lambda x: x[\"finish\"])\n",
    "    return pd.DataFrame(tasks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Find overlaps** We find overlapped tasks using pandas, please not this implementaiton is not effient however we use it here for illustration perpopse, in production you need to consider using better data structure like segment tree to find overlappoing tasks efficietly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_task_overlaps(possible_tasks):\n",
    "    overlapping_tasks = {}\n",
    "    for task in possible_tasks.task.unique():\n",
    "        start, finish = possible_tasks[possible_tasks.task == task].iloc[0][[\"start\", \"finish\"]].values\n",
    "        overlapping_tasks_ = possible_tasks[(possible_tasks.start >= start) & (possible_tasks.start < finish)]\n",
    "        overlapping_tasks_ = list(overlapping_tasks_.task.unique())\n",
    "        if len(overlapping_tasks_) > 1:\n",
    "            overlapping_tasks[task] = overlapping_tasks_\n",
    "    return overlapping_tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Optimiz** we define the optimization problem. (break it down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedual_tasks(tasks):\n",
    "    model = ConcreteModel()\n",
    "\n",
    "    #data\n",
    "    possible_tasks = compute_possible_tasks(tasks)\n",
    "    tasks = possible_tasks.task.values\n",
    "    w = {r.task: r.weight for _, r in possible_tasks[possible_tasks.task == tasks].iterrows()}\n",
    "\n",
    "    #constarint data\n",
    "    overlapping_tasks = find_task_overlaps(possible_tasks)\n",
    "    task_groups = possible_tasks[\"task_group\"].unique()\n",
    "\n",
    "    #variables\n",
    "    model.x = Var(tasks, within=Binary )\n",
    "\n",
    "    #objective\n",
    "    model.value = Objective(expr = sum(w[i]*model.x[i] for i in tasks), sense = maximize )\n",
    "\n",
    "    #constraints\n",
    "    @model.Constraint(task_groups)\n",
    "    def one_each_group(m, tg):\n",
    "        return sum(m.x[task] for task in possible_tasks[possible_tasks[\"task_group\"] == tg][\"task\"].unique()) <= 1\n",
    "\n",
    "    @model.Constraint(overlapping_tasks.keys())\n",
    "    def one_each_overlap(m, t):\n",
    "        return sum(m.x[task] for task in overlapping_tasks[t]) <= 1\n",
    "\n",
    "    #solve\n",
    "    opt = SolverFactory('glpk')\n",
    "    result_obj = opt.solve(model)\n",
    "    selected = [k for k, v in model.x.get_values().items() if v == 1]\n",
    "    \n",
    "    #formate resutls\n",
    "    results = (possible_tasks\n",
    "          .loc[possible_tasks.task.isin(selected)]\n",
    "          .sort_values(by=['start'])\n",
    "          .set_index(\"task_group\")\n",
    "          [[\"start\", \"finish\", \"duration\", \"weight\"]])\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "results = schedual_tasks(tasks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>finish</th>\n",
       "      <th>duration</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T6</th>\n",
       "      <td>10.00</td>\n",
       "      <td>10.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T4</th>\n",
       "      <td>10.25</td>\n",
       "      <td>10.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1</th>\n",
       "      <td>11.75</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T3</th>\n",
       "      <td>12.75</td>\n",
       "      <td>13.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T2</th>\n",
       "      <td>13.25</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T5</th>\n",
       "      <td>14.25</td>\n",
       "      <td>14.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            start  finish  duration  weight\n",
       "task_group                                 \n",
       "T6          10.00   10.25      0.25       5\n",
       "T4          10.25   10.50      0.25       1\n",
       "T1          11.75   12.00      0.25       3\n",
       "T3          12.75   13.25      0.50       5\n",
       "T2          13.25   14.00      0.75       3\n",
       "T5          14.25   14.75      0.50       3"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.weight.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Baseline sanity check** to verify that our solution is working fine, we set a greedy algorithm that take the most valuable tasks first and eliminate all conflicting tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def solve_by_elemination(tasks):\n",
    "    schedual = []\n",
    "    possible_tasks = compute_possible_tasks(tasks)\n",
    "    possible_tasks_ = possible_tasks.copy().sort_values(by=['weight'], ascending=False)\n",
    "    for i in range(100):\n",
    "        try:\n",
    "            task, task_group, start, finish = possible_tasks_.iloc[i][[\"task\", \"task_group\", \"start\", \"finish\"]]\n",
    "            possible_tasks_ = possible_tasks_[~((possible_tasks_.start >= start) & (possible_tasks_.start < finish) & ((possible_tasks_.task != task)))]\n",
    "            possible_tasks_ = possible_tasks_[~((possible_tasks_.finish > start) & (possible_tasks_.finish <= finish) & ((possible_tasks_.task != task)))]\n",
    "            possible_tasks_ = possible_tasks_[(possible_tasks_.task_group != task_group) | (possible_tasks_.task == task ) ]\n",
    "            schedual += [task]\n",
    "        except:\n",
    "            break\n",
    "    return possible_tasks[possible_tasks.task.isin(schedual)]\n",
    "\n",
    "solve_by_elemination(tasks).weight.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we see that our optimization is surpassing the baseline and the resuls make sens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We don't know the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking back to what we have right now, we have clients that we want to meet during a day, each client provide a there free time slots, and each meating have specfic duration and imprtance associated with it, your job is to schedual the meetins to maximize the importance you get from the meetings. You have realized the problem complexity, switch gears from building complex algorithm to build simple model and use pyomo optimization libarary to solve it, so far so good.\n",
    "\n",
    "Now, you can imagin that imprtance of each client is not pre defined, actually, we learnt it on the way. Is it possible to extend our algorithm to optmize the schedual and learn importance in the same time?. To answer this question, lets focus on the learning aspect. Imagin that you are travelling to new country, you want to get some lunch and you find 2 restorants nearby and you want to know which one to choose. Your measure from quality is on scale from 0 to 1, where 0 means you dont like the food at all and 1 for perfect food. If you tried one restorant for 10 times, you can compute the mean and standard diviation and form a confidence interval of the food quality at that restorant. Comparing two restorants is somehow tricky. If one resturant got 70% score and another get 75%, you could expect that the second is a better one, however it could be due to random reason. To establish healthy decision, you could use statistical procedures like T-Test or ANOVA to test if the difference is statistically significant or not.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T-Test/ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "while with T-test it is prety much safe to decide which resturant is the best choose, you will need to try them all n times to draw the conclusion. That is simply not how we will solve it as humans, we dont try bad restorants hundred times to establish statisical significance! Instead people will try resorants at random and come back to the best ones they found so far, sometimes they will explore new options. This key in this method is to balance exploration of new restorants and exploitation of the best restorants. The value you loose due to exploring none optimal choices is called regret, and you basiclly want minimize your regret of going to bad resorants. Fortunatly, the exploration vs. exploitation problme known as Multi Arm Bandit MAB (add info in a side box) is well studied one, and in fact there are provably optimal statigies to solve it. In general we could reley on the principle of optmizm in face of uncertinatiy, the idea is to choose the best know choices when we are not certain.\n",
    "\n",
    "explain UCB1 algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UCB1 and regret plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going from resturants to optimization algorithms, we want to utilize the same principle optmizm in face of uncertainity. To make it possible it is better to model the optmization algorithm like an agent that interact with some enviroment to learn the about the problem and find optmial solution. Our model have the following components:\n",
    "\n",
    "- **Problem**: which encapsulate the objective, the constraints, the structue of the problem and all otehr info except for the problem wights.\n",
    "- **Parameters**: encapsulate the wieght of the problem \n",
    "- **Solver**: the optmizer we use to solve the problem \n",
    "- **Oracle**: the envirment sensor that will tell us the weights of the solution\n",
    "- **Agent**: which take the problme, parameters and solver to solve the problem and then use the oracle to observe the solution quality.\n",
    "\n",
    "#TODO draw a schmatic of the env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Oracle:\n",
    "    def observe(self, problem, solution):\n",
    "        pass\n",
    "        \n",
    "class Solver:\n",
    "    def solve(self, problem, weights):\n",
    "        pass\n",
    "    \n",
    "class Problem:\n",
    "    pass\n",
    "\n",
    "class ProblemModel:\n",
    "    def get_all_weights(self):\n",
    "        pass\n",
    "    \n",
    "    def set_weights(self, weights):\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our schedualing example, the problem will hold the meetings informations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskSchedualingProblem(Problem):\n",
    "    def __init__(self, tasks):\n",
    "        self.tasks = tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters will store the weights of each possilbe meeting, note that all possible tasks belong to parant task have the same weight. For conviniance, we set two modes to initialize the wieghts random and know waits. Know wieghts will be used to solve the problem as we know it, while random initial weights will be used whenever are in bandit mode. (rephrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskSchedualingProblemModel(ProblemModel):\n",
    "    def __init__(self, tasks, weights_known=False):\n",
    "        if weights_known:\n",
    "            self.weights = dict(compute_possible_tasks(tasks)[[\"task_group\", \"weight\"]].drop_duplicates().values)\n",
    "        else:\n",
    "            self.weights = {i: random.random() for i in compute_possible_tasks(tasks)[\"task_group\"].drop_duplicates().values}\n",
    "        self.arms = self.weights.keys()  \n",
    "        \n",
    "    def get_all_weights(self):\n",
    "        return self.weights\n",
    "    \n",
    "    def set_weights(self, weights):\n",
    "        for k, v in weights.items():\n",
    "            self.weights[k] = v\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solver will simply call the schedual taks function we defined before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskSchedualingSolver(Solver):\n",
    "    def __init__(self):\n",
    "        pass \n",
    "    \n",
    "    def solve(self, problem, weights):\n",
    "        tasks = [task[:4] + [weights[task[0]]] for task in problem.tasks]\n",
    "        return schedual_tasks(tasks).index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Oracle models our enviroment, depending on the nature of the enviroment the observations could be true values or noisy readings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskSchedualingOracle(Oracle):\n",
    "    def __init__(self, tasks, noise_factor=3.0):\n",
    "        self.weights = dict(compute_possible_tasks(tasks)[[\"task_group\", \"weight\"]].drop_duplicates().values)\n",
    "        self.arms = self.weights.keys()  \n",
    "        self.noise_factor = noise_factor\n",
    "        \n",
    "    def get_weight(self, x, noisy=False):\n",
    "        if noisy:\n",
    "            return self.weights[x] + (random.random() - 0.5) * self.noise_factor\n",
    "        else:\n",
    "            return self.weights[x]\n",
    "        \n",
    "    def observe(self, problem, solution, noisy=False):\n",
    "        return [self.get_weight(x, noisy=noisy) for x in solution]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 1545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem = TaskSchedualingProblem(tasks)\n",
    "problem_model = TaskSchedualingProblemModel(tasks, weights_known=True)\n",
    "oracle = TaskSchedualingOracle(tasks, noise_factor=5)\n",
    "solver = TaskSchedualingSolver()\n",
    "sln = solver.solve(problem, problem_model.get_all_weights())\n",
    "sum(oracle.observe(problem, sln, noisy=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 1546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_model_uncertain = TaskSchedualingProblemModel(tasks, weights_known=False)\n",
    "sln = solver.solve(problem, problem_model_uncertain.get_all_weights())\n",
    "sum(oracle.observe(problem, sln, noisy=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombUcb1:\n",
    "    def __init__(self, problem, problem_model, solver, oracle, mode='Max'):\n",
    "        self.problem = problem\n",
    "        self.solver = solver\n",
    "        self.oracle = oracle\n",
    "        self.arms = problem_model.arms\n",
    "        self.mode = mode\n",
    "        self.init_algorithm()\n",
    "\n",
    "    def init_algorithm(self):\n",
    "        uu = {i: 0.0 for i in self.arms}\n",
    "        w = {i: 0.0 for i in self.arms}\n",
    "        t = 0\n",
    "        for arm in uu.keys():\n",
    "            if self.mode == 'Max':\n",
    "                uu[arm] = 1.0\n",
    "            elif self.mode == 'Min':\n",
    "                uu[arm] = 0.0\n",
    "            else:\n",
    "                raise Exception('Mode is only Max or Min')\n",
    "        solution_exists = True\n",
    "\n",
    "        while ((self.mode == 'Min' and np.min(list(uu.values())) == 0)\n",
    "                                        or (self.mode == 'Max' and np.max(list(uu.values())) == 1.0)):\n",
    "            At = self.solver.solve(self.problem, uu)\n",
    "            if At is None:\n",
    "                break\n",
    "            AtW = self.oracle.observe(self.problem, At, noisy=True)\n",
    "\n",
    "            for idx, e in enumerate(At):\n",
    "                w[e] = AtW[idx]\n",
    "                if self.mode == 'Max':\n",
    "                    uu[e] = 0.0\n",
    "                elif self.mode == 'Min':\n",
    "                    uu[e] = 1.0\n",
    "                else:\n",
    "                    raise Exception('Mode is only Max or Min')\n",
    "            t += 1\n",
    "        self.weights = w\n",
    "        self.time_steps = {i: 1.0 for i in w.keys()}\n",
    "        self.t = t\n",
    "\n",
    "    def bandit_iter(self):\n",
    "        weights = self.weights\n",
    "        time_steps = self.time_steps\n",
    "        t = self.t\n",
    "        if self.mode == 'Max':\n",
    "            u_ucb = {i: min(weights[i] + np.sqrt(1.5 * np.log(t)/time_steps[i]), 1.0) for i in weights.keys()}\n",
    "        elif self.mode == 'Min':\n",
    "            u_ucb = {i: max(weights[i] - np.sqrt(1.5 * np.log(t)/time_steps[i]), 0) for i in weights.keys()}\n",
    "        else:\n",
    "            raise Exception('Mode is only Max or Min')\n",
    "        At = self.solver.solve(self.problem, u_ucb)\n",
    "        wAt = self.oracle.observe(self.problem, At)\n",
    "        for idx, e in enumerate(At):\n",
    "            weights[e] = (time_steps[e] * weights[e] + wAt[idx]) / (time_steps[e] + 1)\n",
    "            time_steps[e] += 1\n",
    "        t += 1\n",
    "        self.time_steps = time_steps\n",
    "        self.weights = weights\n",
    "        self.t = t\n",
    "\n",
    "    def solve(self):\n",
    "        weights = self.weights\n",
    "        u_ucb = weights\n",
    "        return self.solver.solve(self.problem, u_ucb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1547,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "b = CombUcb1(problem=problem, problem_model=problem_model_uncertain, solver=solver, oracle=oracle, mode='Max')\n",
    "\n",
    "for i in range(5):\n",
    "    print (i)\n",
    "    b.bandit_iter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 1548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sln = solver.solve(problem, b.weights)\n",
    "sum(oracle.observe(problem, sln, noisy=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not only schedualing\n",
    "wait, we can solve problems without knwing the parametrics! What about other problems? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Knapsak with unkown waits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shotest path with unknown waits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend to a team of phone marekters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1549,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents_workload = (\"Alex\", \"Jennifer\", \"Andrew\", \"DeAnna\", \"Jesse\")\n",
    "\n",
    "clients = (\n",
    "    \"Trista\", \"Meredith\", \"Aaron\", \"Bob\", \"Jillian\",\n",
    "    \"Ali\", \"Ashley\", \"Emily\", \"Desiree\", \"Byron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1550,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "def score(agent, client):\n",
    "    try:\n",
    "        s = 1 / (1 + math.exp(-np.dot(agents_v[agent], clients_v[client])))\n",
    "    except:\n",
    "        print (np.dot(agents_v[agent], clients_v[client]))\n",
    "        return random.random()\n",
    "    return s\n",
    "    \n",
    "def generate_matching_problem(agents, clients):\n",
    "    num_samples = len(agents) + len(clients)\n",
    "    samples = sklearn.datasets.make_swiss_roll(num_samples, noise=3, random_state=0)[0]\n",
    "    random.shuffle(samples)\n",
    "    clients_v = {clients[i]: samples[i] for i in range(len(clients))}\n",
    "    agents_v = {agents[i]: samples[i] for i in range(len(agents))}\n",
    "    match_scores = dict(\n",
    "        ((agent, client), score(agent, client))\n",
    "        for agent in agents_workloads\n",
    "        for client in clients)\n",
    "\n",
    "    client_time = {client: random.randint(1, 4) for client in clients}\n",
    "    agents_workload = {agent: random.randint(2, 5) for agent in agents}\n",
    "    \n",
    "    return match_scores, client_time, agents_workload, clients_v, agents_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1551,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_matching(match_scores, client_time, agents_workload):\n",
    "    agents = agents_workloads.keys()\n",
    "    clients = client_time.keys()\n",
    "    \n",
    "    model = pe.ConcreteModel()\n",
    "    model.agents = agents_workloads.keys()\n",
    "    model.clients = clients\n",
    "    model.match_scores = match_scores\n",
    "    model.agents_workload = agents_workload\n",
    "\n",
    "    model.assignments = pe.Var(match_scores.keys(), domain=pe.Binary)\n",
    "    model.objective = pe.Objective(\n",
    "            expr=pe.summation(model.match_scores, model.assignments),\n",
    "            sense=pe.maximize)\n",
    "\n",
    "    @model.Constraint(model.agents)\n",
    "    def respect_workload(model, agent):\n",
    "        return sum(model.assignments[agent, client] * client_time[client] for client in model.clients) <= model.agents_workload[agent]\n",
    "\n",
    "    @model.Constraint(model.clients)\n",
    "    def one_agent_per_client(model, client):\n",
    "        return sum(model.assignments[agent, client] for agent in model.agents) <= 1\n",
    "\n",
    "\n",
    "    solver = pe.SolverFactory(\"glpk\")\n",
    "    solver.solve(model)\n",
    "    sln = [k for k, v in model.assignments.get_values().items() if v == 1.0]\n",
    "    return sln, sum(match_scores[i] for i in sln)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1552,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_matching_greedy(match_scores, client_time, agents_workload):\n",
    "    agents = agents_workloads.keys()\n",
    "    clients = client_time.keys()\n",
    "    matching = sorted(match_scores.items(), key=lambda x: -x[1])\n",
    "    clients_indicator = {client: 0 for client in clients}\n",
    "    agents_workload_ = agents_workload.copy()\n",
    "    sln = []\n",
    "    for (agent, client), score in matching:\n",
    "        if clients_indicator[client] == 0 and agents_workload_[agent] >= client_time[client]:\n",
    "            clients_indicator[client] = 1\n",
    "            agents_workload_[agent] -= client_time[client]\n",
    "            sln += [(agent, client)]\n",
    "    return sln, sum([match_scores[i] for i in sln])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1553,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_scores, client_time, agents_workload, clients_v, agents_v = generate_matching_problem(agents, clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('DeAnna', 'Meredith'),\n",
       "  ('Andrew', 'Ashley'),\n",
       "  ('Jesse', 'Jillian'),\n",
       "  ('DeAnna', 'Emily'),\n",
       "  ('Jesse', 'Byron'),\n",
       "  ('Jennifer', 'Bob'),\n",
       "  ('Alex', 'Trista')],\n",
       " 7.0)"
      ]
     },
     "execution_count": 1554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve_matching(match_scores, client_time, agents_workload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('Alex', 'Trista'),\n",
       "  ('Jennifer', 'Bob'),\n",
       "  ('Andrew', 'Meredith'),\n",
       "  ('DeAnna', 'Aaron'),\n",
       "  ('DeAnna', 'Jillian'),\n",
       "  ('Jesse', 'Ashley')],\n",
       " 6.0)"
      ]
     },
     "execution_count": 1555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve_matching_greedy(match_scores, client_time, agents_workload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1556,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the matching optimization problem\n",
    "class MatchingProblem(Problem):\n",
    "    def __init__(self, match_scores, client_time, agents_workload, agents_v, clients_v):\n",
    "        self.match_scores = match_scores\n",
    "        self.agents_workload = agents_workload\n",
    "        self.client_time = client_time\n",
    "        self.features = {(agent, client): np.hstack([agents_v[agent], clients_v[client]]) \n",
    "                         for agent, client in match_scores.keys()}\n",
    "\n",
    "\n",
    "class MatchingProblemModel(ProblemModel):\n",
    "    def __init__(self, match_scores, weights_known=False):\n",
    "        if weights_known:\n",
    "            self.weights = match_scores.copy()\n",
    "        else:\n",
    "            self.weights = {i: random.random() for i in match_scores.keys()}\n",
    "        self.arms = self.weights.keys()  \n",
    "        \n",
    "    def get_all_weights(self):\n",
    "        return self.weights\n",
    "    \n",
    "    def set_weights(self, weights):\n",
    "        for k, v in weights.items():\n",
    "            self.weights[k] = v\n",
    "    \n",
    "\n",
    "class MatchingSolver(Solver):\n",
    "    def __init__(self):\n",
    "        pass \n",
    "    \n",
    "    def solve(self, problem, weights):\n",
    "        return solve_matching(weights, problem.client_time, problem.agents_workload)\n",
    "        \n",
    "        \n",
    "class MatchingOracle(Oracle):\n",
    "    def __init__(self, match_scores, noise_factor=3.0):\n",
    "        self.weights = match_scores.copy()\n",
    "        self.arms = self.weights.keys()  \n",
    "        self.noise_factor = noise_factor\n",
    "        \n",
    "    def get_weight(self, x, noisy=False):\n",
    "        if noisy:\n",
    "            return self.weights[x] + (random.random() - 0.5) * self.noise_factor\n",
    "        else:\n",
    "            return self.weights[x]\n",
    "        \n",
    "    def observe(self, problem, solution, noisy=True):\n",
    "        return [self.get_weight(x, noisy=noisy) for x in solution]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1590,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CombTS\n",
    "class CombLinTs:\n",
    "    def __init__(self, problem, p_lambda, p_sigma, solver, oracle):\n",
    "        self.d = np.array(list(problem.features.values())).shape[1]\n",
    "        self.p_lambda = p_lambda\n",
    "        self.p_sigma = p_sigma\n",
    "        self.sigma = (p_lambda ** 2) * np.eye(self.d)\n",
    "        self.theta = np.zeros(self.d)\n",
    "        self.solver = solver\n",
    "        self.oracle = oracle\n",
    "        \n",
    "    def sample_theta(self):\n",
    "        return np.random.multivariate_normal(self.theta, self.sigma)\n",
    "    \n",
    "    def update_params(self, wAt):\n",
    "        theta = self.theta\n",
    "        sigma = self.sigma\n",
    "        \n",
    "        n = len(wAt)\n",
    "        \n",
    "        for k, v in wAt.items():\n",
    "            f_vec = np.expand_dims(problem.features[k], axis=1)\n",
    "            t1 = np.matmul(sigma, np.matmul(f_vec, f_vec.T))\n",
    "            t2 = np.matmul(f_vec.T, np.matmul(sigma, f_vec)) + self.p_sigma ** 2\n",
    "            t3 = np.matmul(sigma, f_vec)\n",
    "            t4 = np.matmul(np.matmul(f_vec.T, sigma), f_vec) + self.p_sigma ** 2\n",
    "            theta = np.matmul((np.eye(sigma.shape[0]) - t1 / t2), theta) + \\\n",
    "                        np.squeeze(t3 / t4) * wAt[k]\n",
    "\n",
    "            t1 = np.matmul(np.matmul(sigma, np.matmul(f_vec, f_vec.T)), sigma)\n",
    "            t2 = np.matmul(np.matmul(f_vec.T, sigma), f_vec) + self.p_sigma ** 2\n",
    "            sigma = sigma - t1/t2\n",
    "    \n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "            \n",
    "    def bandit_iter(self, problem):\n",
    "        theta = self.sample_theta()\n",
    "        At, _ = self.solver.solve(problem, {k: np.dot(v, theta) for k, v in problem.features.items()})\n",
    "        wAt = self.oracle.observe(problem, At, noisy=True)\n",
    "        wAt = dict(zip(At, wAt))\n",
    "        self.update_params(wAt)\n",
    "        \n",
    "    def solve(self, problem):\n",
    "        theta = self.sample_theta()\n",
    "        sln, _ = self.solver.solve(problem, {k: np.dot(v, theta) for k, v in problem.features.items()})\n",
    "        return sln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1634,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.00008340099822"
      ]
     },
     "execution_count": 1634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_scores, client_time, agents_workload, clients_v, agents_v = generate_matching_problem(agents, clients)\n",
    "problem = MatchingProblem(match_scores, client_time, agents_workload, agents_v, clients_v)\n",
    "problem_model = MatchingProblemModel(match_scores, weights_known=False)\n",
    "oracle = MatchingOracle(match_scores, noise_factor=2)\n",
    "solver = MatchingSolver()\n",
    "sln, w = solver.solve(problem, problem_model.get_all_weights())\n",
    "np.sum(oracle.observe(problem, At, noisy=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1635,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 1635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_model = MatchingProblemModel(match_scores, weights_known=True)\n",
    "sln, w = solver.solve(problem, problem_model.get_all_weights())\n",
    "np.sum(oracle.observe(problem, sln, noisy=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "8.0\n",
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "8.0\n",
      "8.0\n",
      "8.0\n"
     ]
    }
   ],
   "source": [
    "p_lambda = 10.\n",
    "p_sigma = 0.1\n",
    "features_dim =  10\n",
    "bandit = CombLinTs(p_lambda=p_lambda,\n",
    "                     p_sigma=p_sigma, problem=problem, solver=solver, oracle=oracle)\n",
    "\n",
    "for i in range(100):\n",
    "    bandit.bandit_iter(problem=problem)\n",
    "    if i % 10 == 0:\n",
    "        At = bandit.solve(problem)\n",
    "        print (np.sum(oracle.observe(problem, At, noisy=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* scale up all pairs \n",
    "* We assumed all weight are random, what if they are normal with different means and variances\n",
    "* Emperical bayes for new joiners \n",
    "* Extend to team\n",
    "* spending more time is useful\n",
    "* Streamline with Tensorflow probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 1352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: the bandit example\n",
    "# TODO: drwa gunt chart\n",
    "# TODO: shortest path \n",
    "# TODO: Knapsack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to do both selection and schedualing, learn improtrance of each client, start from reasonable wights for faster exporation or add more cool features. Very well, we will go through after we introduce some cool tools. For the time being, lets sharpen our skills by solving 2 other problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The dauntless conclusion**: *Be a modeling super star, dont fear missing info!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibloigraphy (Text style like in intordction to algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
